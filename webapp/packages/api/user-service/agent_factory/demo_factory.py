# webapp/packages/api/user-service/agent_factory/demo_factory.py
from .prompts import how_to_build_demo_app_template
from litellm import acompletion
from models.demo import GenerateDemoCodeRequest, GenerateDemoCodeResponse, DeployedApi
import json

def _format_api_docs(apis: list[DeployedApi]) -> str:
    """Formats the API information into a markdown string for the prompt."""
    if not apis:
        return "No APIs selected."
    
    docs_parts = []
    for api in apis:
        input_schema_str = json.dumps(api.input_schema, indent=2)
        output_schema_str = json.dumps(api.output_schema, indent=2)
        
        doc = f"""### API: `{api.friendly_name}`
**Endpoint**: `POST /rest/{api.friendly_name}`
**Description**: {api.description}

**Input Schema (Request Body JSON):**
```json
{input_schema_str}
```

**Output Schema (Response Body JSON):**
```json
{output_schema_str}
```
"""
        docs_parts.append(doc)
    
    return "\n\n".join(docs_parts)


async def generate_demo_code(request: GenerateDemoCodeRequest) -> GenerateDemoCodeResponse:
    """
    Generates HTML, CSS, and JS for a demo app based on a user prompt and selected APIs.
    """
    api_docs = _format_api_docs(request.selected_apis)
    
    system_prompt = how_to_build_demo_app_template.format(
        api_docs=api_docs,
        user_prompt=request.user_prompt
    )

    messages = [
        {"role": "system", "content": "You are a helpful assistant that generates web application code in JSON format."},
        {"role": "user", "content": system_prompt}
    ]

    model = request.composer_model_config.model
    provider = request.composer_model_config.provider
    config = request.composer_model_config.parameters.copy()
    if provider == "openai":
        config['response_format'] = { "type": "json_object" }

    response = await acompletion(
        model=f"{provider}/{model}",
        messages=messages,
        **config
    )

    response_content = response.choices[0].message.content
    try:
        # Clean up potential markdown
        if response_content.strip().startswith("```json"):
            response_content = response_content.strip()[len("```json"):].strip()
        if response_content.strip().endswith("```"):
            response_content = response_content.strip()[:-len("```")].strip()
            
        code_json = json.loads(response_content)
        return GenerateDemoCodeResponse(**code_json)
    except (json.JSONDecodeError, TypeError) as e:
        print(f"Error parsing demo code JSON from LLM: {e}")
        print(f"LLM response was: {response_content}")
        raise ValueError(f"Could not parse the code generated by the model. Response:\n{response_content}")