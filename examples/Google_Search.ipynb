{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install `gofannon`"
      ],
      "metadata": {
        "id": "mODCUkNvHIBN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChFUyFfOG3t-",
        "outputId": "01819f4c-9ba4-4323-aa2f-9479d5586eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: git+https://github.com/rawkintrevo/gofannon.git@31#egg=gofannon[google] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gofannon (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install \"git+https://github.com/The-AI-Alliance/gofannon.git@main#egg=gofannon[google]\" --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "from gofannon.google_search.google_search import GoogleSearch\n",
        "\n",
        "google_search = GoogleSearch(api_key=userdata.get(\"google_search\"), engine_id=\"75be790deec0c42f3\")\n",
        "\n",
        "\n",
        "# Create an OpenAI client with your deepinfra token and endpoint\n",
        "openai = OpenAI(\n",
        "    api_key=userdata.get('deepinfra'),\n",
        "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
        ")\n",
        "\n",
        "tool_list =  [google_search]\n",
        "tool_map = {f.name: f.fn for f in tool_list}\n",
        "tool_desc_list = [f.definition for f in tool_list]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoVm1CqXHfuy",
        "outputId": "f4a81429-ceb0-4036-98c3-d776f4541e41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [

          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What newsworthy events happened at the Paris AI Summit?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# let's send the request and print the response\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "    messages=messages,\n",
        "    tools=tool_desc_list,\n",
        "    tool_choice=\"auto\",\n",
        ")\n",
        "tool_calls = response.choices[0].message.tool_calls\n",
        "for tool_call in tool_calls:\n",
        "    print(tool_call.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaYx9uAUjwle",
        "outputId": "419e36cb-4986-412e-b9ec-766f5e693576"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'call_nwPc50kSHkjiH5NV6wW6phWH', 'function': {'arguments': '{\"query\": \"Paris AI Summit news\", \"num_results\": 5}', 'name': 'google_search'}, 'type': 'function'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(response.choices[0].message)\n",
        "\n",
        "for tool_call in tool_calls:\n",
        "  function_name = tool_call.function.name\n",
        "  function_args = json.loads(tool_call.function.arguments)\n",
        "  function_response = tool_map[function_name](**function_args)\n",
        "\n",
        "  # extend conversation with function response\n",
        "  messages.append({\n",
        "      \"tool_call_id\": tool_call.id,\n",
        "      \"role\": \"tool\",\n",
        "      \"content\": function_response,\n",
        "  })\n",
        "\n",
        "\n",
        "# get a new response from the model where it can see the function responses\n",
        "second_response = openai.chat.completions.create(\n",
        "  model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "  messages=messages,\n",
        "  tools=tool_desc_list,\n",
        "  tool_choice=\"auto\",\n",
        ")\n",
        "\n",
        "print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ZW1317lr9e",
        "outputId": "903385bf-ebed-4460-c0c4-b0415438cfe0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Paris AI Summit, also known as the Artificial Intelligence Action Summit, was a recent event that brought together world leaders, CEOs, and experts to discuss the future of artificial intelligence. Some of the newsworthy events that took place at the summit include:\n",
            "\n",
            "* France and the EU promising to cut red tape on tech regulation to make it easier for AI to flourish in the region\n",
            "* Discussions on the destiny of the tech revolution and its potential impact on society\n",
            "* Vice President JD Vance's address to European and Asian leaders, highlighting the importance of AI in shaping the future\n",
            "* A call for projects from the Paris Peace Forum, aiming to address global challenges through AI\n",
            "* A statement from Dario Amodei, appreciating the French government's efforts to bring together AI companies, researchers, and policymakers.\n",
            "\n",
            "These events and discussions demonstrate the growing interest in AI and its potential to address global challenges, as well as the need for regulation and cooperation to ensure its responsible development and use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result\n",
        "\n",
        "The Paris AI Summit took place on Feburary 10th and 11th 2025, well after Llama 3.3 was trained. Yet, by Googling the event, the LLM is able to provide an accurate recap of the event."
      ],
      "metadata": {
        "id": "FF6cPDqVnDKF"
      }
    }
  ]
}